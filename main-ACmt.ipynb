{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO5mI/luqrA0uV7bpVRTG9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljtamang/codeBERT-QG/blob/master/main-ACmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install pacakages required for successfully running this project."
      ],
      "metadata": {
        "id": "IKKRzu4LYvvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install psutil\n",
        "# !pip install h5py \n",
        "# !pip install typing-extensions \n",
        "# !pip install wheel \n",
        "!pip install blue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv_8MJCYAgMW",
        "outputId": "bf1e91f3-35e1-4841-b7ff-433110737ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting blue\n",
            "  Downloading blue-0.9.1-py3-none-any.whl (10 kB)\n",
            "Collecting black==22.1.0\n",
            "  Downloading black-22.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8<5.0.0,>=3.8\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (2.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (4.4.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (2.0.1)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.11.0-py3-none-any.whl (29 kB)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mccabe, pyflakes, pycodestyle, pathspec, mypy-extensions, click, flake8, black, blue\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed black-22.1.0 blue-0.9.1 click-8.1.3 flake8-4.0.1 mccabe-0.6.1 mypy-extensions-1.0.0 pathspec-0.11.0 pycodestyle-2.8.0 pyflakes-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the source code and data used for this project from github repository"
      ],
      "metadata": {
        "id": "f6OLvA_lTB-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ljtamang/codeBERT-QG.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l694QXfL-Uxv",
        "outputId": "f155ff98-b471-4b2f-f4a3-4c336d89c29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'codeBERT-QG'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Counting objects: 100% (233/233), done.\u001b[K\n",
            "remote: Compressing objects: 100% (170/170), done.\u001b[K\n",
            "remote: Total 364 (delta 92), reused 171 (delta 56), pack-reused 131\u001b[K\n",
            "Receiving objects: 100% (364/364), 92.21 MiB | 19.65 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navigate inside the recently downloaded codeBERT-QG project folder"
      ],
      "metadata": {
        "id": "NUHSNiw5amwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd codeBERT-QG\n",
        "#%cd codeBERT-QG/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyA5rzWq9zsO",
        "outputId": "e1c6666a-d842-496d-a1e2-fc27a5241662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/codeBERT-QG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AeVRBiqIGCGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run execute java_script.sh . This will take care of everything and the project should build the model, validate and test it too."
      ],
      "metadata": {
        "id": "Ed53PSxHT04D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#when GPU 1 is available\n",
        "!bash java_script.sh 0 CbQg-ACC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKxlAA1JD9qi",
        "outputId": "a33ed107-31ab-43ec-b9e3-9a052b9199f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-09 16:33:36.212513: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n",
            "Downloading (…)lve/main/config.json: 100% 498/498 [00:00<00:00, 75.6kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:00<00:00, 5.65MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 2.76MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 150/150 [00:00<00:00, 60.3kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 10.0kB/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 499M/499M [00:05<00:00, 91.2MB/s]\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 0\n",
            "INFO:__main__:source_tokens: ['<s>', 'to', '_target', 'file', '</s>', 'mer', 'ges', '_source', 'xml', '_into', '_target', 'xml', '_/', '_target', 'file', '_(', '_target', 'xml', '_is', '_the', '_contents', '_of', '_target', 'file', '_)', '_.', '_returns', '_the', '_resulting', '_xml', '_if', '_it', '_still', '_needs', '_to', '_be', '_written', '_to', '_target', 'file', '_,', '_or', '_null', '_if', '_the', '_file', '_has', '_already', '_been', '_/', '_doesn', \"_'\", '_t', '_need', '_to', '_be', '_updated', '_.', '</s>', '@', '_Null', 'able', '_public', '_static', '_String', '_merge', '_X', 'ml', '_(', '_@', '_Not', '_Null', '_Rend', 'ering', '_Context', '_context', '_,', '_String', '_source', '_X', 'ml', '_,', '_String', '_target', '_X', 'ml', '_,', '_File', '_target', '_File', '_)', '_{', '_boolean', '_ok', '_;', '_String', '_file', '_Name', '_=', '_target', '_File', '_.', '_get', '_Name', '_(', '_)', '_;', '_String', '_contents', '_;', '_if', '_(', '_file', '_Name', '_.', '_equals', '_(', '_S', 'dk', '_Const', 'ants', '_.', '_FN', '_AND', 'RO', 'ID', '_MAN', 'IF', 'EST', '_XML', '_)', '_)', '_{', '_Document', '_current', '_Document', '_=', '_X', 'ml', '_Ut', 'ils', '_.', '_parse', '_Document', '_Sil', 'ently', '_(', '_target', '_X', 'ml', '_,', '_BO', 'OL', '_)', '_;', '_assert', '_current', '_Document', '_!=', '_null', '_:', '_target', '_X', 'ml', '_+', '_STR', 'ING', '_;', '_Document', '_fragment', '_=', '_X', 'ml', '_Ut', 'ils', '_.', '_parse', '_Document', '_Sil', 'ently', '_(', '_source', '_X', 'ml', '_,', '_BO', 'OL', '_)', '_;', '_assert', '_fragment', '_!=', '_null', '_:', '_source', '_X', 'ml', '_+', '_STR', 'ING', '_;', '_contents', '_=', '_merge', '_Manifest', '_(', '_target', '_File', '_,', '_target', '_X', 'ml', '_,', '_source', '_X', 'ml', '_)', '_;', '_ok', '_=', '_contents', '_!=', '_null', '_;', '_}', '_else', '_{', '_String', '_parent', '_Folder', '_Name', '_=', '_target', '_File', '_.', '_get', '_Parent', '_File', '_(', '_)', '_.', '_get', '_Name', '_(', '_)', '_;', '_Resource', '_Folder', '_Type', '_folder', '_Type', '_=', '_Resource', '_Folder', '_Type', '_.', '_get', '_Folder', '_Type', '_(', '_parent', '_Folder', '_Name', '_)', '_;', '_contents', '_=', '_merge', '_Resource', '_File', '_(', '_context', '_,', '_target', '_X', 'ml', '_,', '_source', '_X', 'ml', '_,', '_file', '_Name', '_,', '_folder', '_Type', '_)', '_;', '_ok', '_=', '_contents', '_!=', '_null', '_;', '_}', '_if', '_(', '_!', '_ok', '_)', '_{', '_contents', '_=', '_wrap', '_With', '_Merge', '_Conflict', '_(', '_target', '_X', 'ml', '_,', '_source', '_X', 'ml', '_)', '_;', '_context', '_.', '_get', '_Warn', 'ings', '_(', '_)', '_.', '_add', '_(', '_String', '_.', '_format', '_(', '_STR', 'ING', '_,', '_target', '_File', '_.', '_get', '_Name', '_(', '_)', '_)', '_)', '_;', '_}', '_return', '_contents', '_;', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 560 1002 21710 2 2089 5641 1300 47858 88 1002 47858 1589 1002 21710 36 1002 47858 16 5 13654 9 1002 21710 4839 479 2886 5 5203 49377 114 24 202 782 7 28 1982 7 1002 21710 2156 50 23796 114 5 2870 34 416 57 1589 630 128 326 240 7 28 4752 479 2 1039 44840 868 285 25156 26602 19388 1577 18517 36 787 1491 44840 29110 2961 43885 5377 2156 26602 1300 1577 18517 2156 26602 1002 1577 18517 2156 8655 1002 8655 4839 25522 49378 15983 25606 26602 2870 10704 5457 1002 8655 479 120 10704 36 4839 25606 26602 13654 25606 114 36 2870 10704 479 27601 36 208 43357 11242 3277 479 38721 4248 8727 2688 12408 7025 4923 46917 4839 4839 25522 27246 595 27246 5457 1577 18517 11183 5290 479 43756 27246 8897 7240 36 1002 1577 18517 2156 9963 3384 4839 25606 18088 595 27246 49333 23796 4832 1002 1577 18517 2055 20857 1862 25606 27246 37903 5457 1577 18517 11183 5290 479 43756 27246 8897 7240 36 1300 1577 18517 2156 9963 3384 4839 25606 18088 37903 49333 23796 4832 1300 1577 18517 2055 20857 1862 25606 13654 5457 19388 41373 36 1002 8655 2156 1002 1577 18517 2156 1300 1577 18517 4839 25606 15983 5457 13654 49333 23796 25606 35524 1493 25522 26602 4095 47728 10704 5457 1002 8655 479 120 7783 8655 36 4839 479 120 10704 36 4839 25606 13877 47728 7773 32038 7773 5457 13877 47728 7773 479 120 47728 7773 36 4095 47728 10704 4839 25606 13654 5457 19388 13877 8655 36 5377 2156 1002 1577 18517 2156 1300 1577 18517 2156 2870 10704 2156 32038 7773 4839 25606 15983 5457 13654 49333 23796 25606 35524 114 36 27785 15983 4839 25522 13654 5457 10438 590 46417 35856 36 1002 1577 18517 2156 1300 1577 18517 4839 25606 5377 479 120 26367 1033 36 4839 479 1606 36 26602 479 7390 36 20857 1862 2156 1002 8655 479 120 10704 36 4839 4839 4839 25606 35524 671 13654 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'How', '_be', '_it', '_written', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 6179 28 24 1982 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 1\n",
            "INFO:__main__:source_tokens: ['<s>', 'to', '_be', '_written', '_to', '_target', 'file', '</s>', 'mer', 'ges', '_source', 'xml', '_into', '_target', 'xml', '_/', '_target', 'file', '_(', '_target', 'xml', '_is', '_the', '_contents', '_of', '_target', 'file', '_)', '_.', '_returns', '_the', '_resulting', '_xml', '_if', '_it', '_still', '_needs', '_to', '_be', '_written', '_to', '_target', 'file', '_,', '_or', '_null', '_if', '_the', '_file', '_has', '_already', '_been', '_/', '_doesn', \"_'\", '_t', '_need', '_to', '_be', '_updated', '_.', '</s>', '@', '_Null', 'able', '_public', '_static', '_String', '_merge', '_X', 'ml', '_(', '_@', '_Not', '_Null', '_Rend', 'ering', '_Context', '_context', '_,', '_String', '_source', '_X', 'ml', '_,', '_String', '_target', '_X', 'ml', '_,', '_File', '_target', '_File', '_)', '_{', '_boolean', '_ok', '_;', '_String', '_file', '_Name', '_=', '_target', '_File', '_.', '_get', '_Name', '_(', '_)', '_;', '_String', '_contents', '_;', '_if', '_(', '_file', '_Name', '_.', '_equals', '_(', '_S', 'dk', '_Const', 'ants', '_.', '_FN', '_AND', 'RO', 'ID', '_MAN', 'IF', 'EST', '_XML', '_)', '_)', '_{', '_Document', '_current', '_Document', '_=', '_X', 'ml', '_Ut', 'ils', '_.', '_parse', '_Document', '_Sil', 'ently', '_(', '_target', '_X', 'ml', '_,', '_BO', 'OL', '_)', '_;', '_assert', '_current', '_Document', '_!=', '_null', '_:', '_target', '_X', 'ml', '_+', '_STR', 'ING', '_;', '_Document', '_fragment', '_=', '_X', 'ml', '_Ut', 'ils', '_.', '_parse', '_Document', '_Sil', 'ently', '_(', '_source', '_X', 'ml', '_,', '_BO', 'OL', '_)', '_;', '_assert', '_fragment', '_!=', '_null', '_:', '_source', '_X', 'ml', '_+', '_STR', 'ING', '_;', '_contents', '_=', '_merge', '_Manifest', '_(', '_target', '_File', '_,', '_target', '_X', 'ml', '_,', '_source', '_X', 'ml', '_)', '_;', '_ok', '_=', '_contents', '_!=', '_null', '_;', '_}', '_else', '_{', '_String', '_parent', '_Folder', '_Name', '_=', '_target', '_File', '_.', '_get', '_Parent', '_File', '_(', '_)', '_.', '_get', '_Name', '_(', '_)', '_;', '_Resource', '_Folder', '_Type', '_folder', '_Type', '_=', '_Resource', '_Folder', '_Type', '_.', '_get', '_Folder', '_Type', '_(', '_parent', '_Folder', '_Name', '_)', '_;', '_contents', '_=', '_merge', '_Resource', '_File', '_(', '_context', '_,', '_target', '_X', 'ml', '_,', '_source', '_X', 'ml', '_,', '_file', '_Name', '_,', '_folder', '_Type', '_)', '_;', '_ok', '_=', '_contents', '_!=', '_null', '_;', '_}', '_if', '_(', '_!', '_ok', '_)', '_{', '_contents', '_=', '_wrap', '_With', '_Merge', '_Conflict', '_(', '_target', '_X', 'ml', '_,', '_source', '_X', 'ml', '_)', '_;', '_context', '_.', '_get', '_Warn', 'ings', '_(', '_)', '_.', '_add', '_(', '_String', '_.', '_format', '_(', '_STR', 'ING', '_,', '_target', '_File', '_.', '_get', '_Name', '_(', '_)', '_)', '_)', '_;', '_}', '_return', '_contents', '_;', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 560 28 1982 7 1002 21710 2 2089 5641 1300 47858 88 1002 47858 1589 1002 21710 36 1002 47858 16 5 13654 9 1002 21710 4839 479 2886 5 5203 49377 114 24 202 782 7 28 1982 7 1002 21710 2156 50 23796 114 5 2870 34 416 57 1589 630 128 326 240 7 28 4752 479 2 1039 44840 868 285 25156 26602 19388 1577 18517 36 787 1491 44840 29110 2961 43885 5377 2156 26602 1300 1577 18517 2156 26602 1002 1577 18517 2156 8655 1002 8655 4839 25522 49378 15983 25606 26602 2870 10704 5457 1002 8655 479 120 10704 36 4839 25606 26602 13654 25606 114 36 2870 10704 479 27601 36 208 43357 11242 3277 479 38721 4248 8727 2688 12408 7025 4923 46917 4839 4839 25522 27246 595 27246 5457 1577 18517 11183 5290 479 43756 27246 8897 7240 36 1002 1577 18517 2156 9963 3384 4839 25606 18088 595 27246 49333 23796 4832 1002 1577 18517 2055 20857 1862 25606 27246 37903 5457 1577 18517 11183 5290 479 43756 27246 8897 7240 36 1300 1577 18517 2156 9963 3384 4839 25606 18088 37903 49333 23796 4832 1300 1577 18517 2055 20857 1862 25606 13654 5457 19388 41373 36 1002 8655 2156 1002 1577 18517 2156 1300 1577 18517 4839 25606 15983 5457 13654 49333 23796 25606 35524 1493 25522 26602 4095 47728 10704 5457 1002 8655 479 120 7783 8655 36 4839 479 120 10704 36 4839 25606 13877 47728 7773 32038 7773 5457 13877 47728 7773 479 120 47728 7773 36 4095 47728 10704 4839 25606 13654 5457 19388 13877 8655 36 5377 2156 1002 1577 18517 2156 1300 1577 18517 2156 2870 10704 2156 32038 7773 4839 25606 15983 5457 13654 49333 23796 25606 35524 114 36 27785 15983 4839 25522 13654 5457 10438 590 46417 35856 36 1002 1577 18517 2156 1300 1577 18517 4839 25606 5377 479 120 26367 1033 36 4839 479 1606 36 26602 479 7390 36 20857 1862 2156 1002 8655 479 120 10704 36 4839 4839 4839 25606 35524 671 13654 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_it', '_need', '_still', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 24 240 202 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 2\n",
            "INFO:__main__:source_tokens: ['<s>', 'a', '_new', '_transformer', '_object', '</s>', 'create', '_a', '_new', '_transformer', '_object', '_that', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '_.', '</s>', 'public', '_Tem', 'plates', '_Handler', '_new', '_Tem', 'plates', '_Handler', '_(', '_)', '_throws', '_Trans', 'former', '_Configuration', '_Exception', '_{', '_return', '_new', '_Styles', 'heet', '_Handler', '_(', '_this', '_)', '_;', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 102 92 40878 7626 2 32845 10 92 40878 7626 14 14023 10 5375 9 5 1300 7 5 898 479 2 15110 9188 40560 41060 92 9188 40560 41060 36 4839 6989 5428 22098 47048 47617 25522 671 92 20427 25148 41060 36 42 4839 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 14023 10 5375 9 5 1300 7 5 898 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 3\n",
            "INFO:__main__:source_tokens: ['<s>', 'a', '_copy', '_of', '_the', '_source', '</s>', 'create', '_a', '_new', '_transformer', '_object', '_that', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '_.', '</s>', 'public', '_Tem', 'plates', '_Handler', '_new', '_Tem', 'plates', '_Handler', '_(', '_)', '_throws', '_Trans', 'former', '_Configuration', '_Exception', '_{', '_return', '_new', '_Styles', 'heet', '_Handler', '_(', '_this', '_)', '_;', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 102 5375 9 5 1300 2 32845 10 92 40878 7626 14 14023 10 5375 9 5 1300 7 5 898 479 2 15110 9188 40560 41060 92 9188 40560 41060 36 4839 6989 5428 22098 47048 47617 25522 671 92 20427 25148 41060 36 42 4839 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_a', '_new', '_transformer', '_object', '_perform', '_to', '_the', '_result', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 10 92 40878 7626 3008 7 5 898 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 4\n",
            "INFO:__main__:source_tokens: ['<s>', 'a', '_new', '_transformer', '_object', '_that', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '</s>', 'create', '_a', '_new', '_transformer', '_object', '_that', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '_.', '</s>', 'public', '_Tem', 'plates', '_Handler', '_new', '_Tem', 'plates', '_Handler', '_(', '_)', '_throws', '_Trans', 'former', '_Configuration', '_Exception', '_{', '_return', '_new', '_Styles', 'heet', '_Handler', '_(', '_this', '_)', '_;', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 102 92 40878 7626 14 14023 10 5375 9 5 1300 7 5 898 2 32845 10 92 40878 7626 14 14023 10 5375 9 5 1300 7 5 898 479 2 15110 9188 40560 41060 92 9188 40560 41060 36 4839 6989 5428 22098 47048 47617 25522 671 92 20427 25148 41060 36 42 4839 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_the', '_code', '_create', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 5 3260 1045 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:__main__:***** Running training *****\n",
            "INFO:__main__:  Num examples = 66514\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  Num epoch = 20\n",
            "epoch 0 loss 3.9517: 100% 2079/2079 [22:31<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 9.41156\n",
            "INFO:__main__:  global_step = 2080\n",
            "INFO:__main__:  train_loss = 3.9517\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:9.41156\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 45.94 | rouge_l = 65.57 | meteor = 27.26 | EM = 23.00 | Precision = 77.78 | Recall = 63.06 | F1 = 67.99 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:45.94140576502264\n",
            "INFO:__main__:  ********************\n",
            "epoch 1 loss 1.493: 100% 2079/2079 [22:30<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 2.29365\n",
            "INFO:__main__:  global_step = 4159\n",
            "INFO:__main__:  train_loss = 1.493\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:2.29365\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 67.73 | rouge_l = 82.33 | meteor = 42.52 | EM = 43.60 | Precision = 89.51 | Recall = 81.69 | F1 = 83.77 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:67.72615556406843\n",
            "INFO:__main__:  ********************\n",
            "epoch 2 loss 0.5998: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.56204\n",
            "INFO:__main__:  global_step = 6238\n",
            "INFO:__main__:  train_loss = 0.5998\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.56204\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 79.52 | rouge_l = 89.09 | meteor = 52.37 | EM = 60.00 | Precision = 91.82 | Recall = 90.06 | F1 = 89.96 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:79.51945278207756\n",
            "INFO:__main__:  ********************\n",
            "epoch 3 loss 0.3234: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.41121\n",
            "INFO:__main__:  global_step = 8317\n",
            "INFO:__main__:  train_loss = 0.3234\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.41121\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 82.74 | rouge_l = 90.69 | meteor = 55.34 | EM = 65.30 | Precision = 92.82 | Recall = 91.49 | F1 = 91.34 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:82.74298421686318\n",
            "INFO:__main__:  ********************\n",
            "epoch 4 loss 0.2098: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.34743\n",
            "INFO:__main__:  global_step = 10396\n",
            "INFO:__main__:  train_loss = 0.2098\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.34743\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 83.51 | rouge_l = 91.00 | meteor = 55.77 | EM = 67.80 | Precision = 93.33 | Recall = 91.73 | F1 = 91.72 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:83.50630134829322\n",
            "INFO:__main__:  ********************\n",
            "epoch 5 loss 0.1472: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.34376\n",
            "INFO:__main__:  global_step = 12475\n",
            "INFO:__main__:  train_loss = 0.1472\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.34376\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 84.54 | rouge_l = 91.78 | meteor = 57.54 | EM = 68.80 | Precision = 92.94 | Recall = 93.27 | F1 = 92.29 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:84.53994420529064\n",
            "INFO:__main__:  ********************\n",
            "epoch 6 loss 0.1106: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.33417\n",
            "INFO:__main__:  global_step = 14554\n",
            "INFO:__main__:  train_loss = 0.1106\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.33417\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 84.06 | rouge_l = 91.39 | meteor = 56.89 | EM = 68.40 | Precision = 92.66 | Recall = 92.81 | F1 = 91.89 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 7 loss 0.0859: 100% 2079/2079 [22:30<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.32994\n",
            "INFO:__main__:  global_step = 16633\n",
            "INFO:__main__:  train_loss = 0.0859\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.32994\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 85.07 | rouge_l = 91.91 | meteor = 57.78 | EM = 70.20 | Precision = 93.24 | Recall = 93.05 | F1 = 92.43 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:85.0738208666568\n",
            "INFO:__main__:  ********************\n",
            "epoch 8 loss 0.0667: 100% 2079/2079 [22:30<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.33158\n",
            "INFO:__main__:  global_step = 18712\n",
            "INFO:__main__:  train_loss = 0.0667\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 85.85 | rouge_l = 92.48 | meteor = 58.83 | EM = 71.40 | Precision = 93.30 | Recall = 94.09 | F1 = 92.91 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:85.85223958569276\n",
            "INFO:__main__:  ********************\n",
            "epoch 9 loss 0.0506: 100% 2079/2079 [22:30<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.35171\n",
            "INFO:__main__:  global_step = 20791\n",
            "INFO:__main__:  train_loss = 0.0506\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 85.56 | rouge_l = 92.05 | meteor = 57.88 | EM = 71.90 | Precision = 93.81 | Recall = 93.14 | F1 = 92.68 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 10 loss 0.0404: 100% 2079/2079 [22:30<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.34531\n",
            "INFO:__main__:  global_step = 22870\n",
            "INFO:__main__:  train_loss = 0.0404\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.06 | rouge_l = 92.31 | meteor = 58.39 | EM = 72.90 | Precision = 93.59 | Recall = 93.56 | F1 = 92.86 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.06102530452385\n",
            "INFO:__main__:  ********************\n",
            "epoch 11 loss 0.0326: 100% 2079/2079 [22:30<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.36253\n",
            "INFO:__main__:  global_step = 24949\n",
            "INFO:__main__:  train_loss = 0.0326\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 85.93 | rouge_l = 92.36 | meteor = 58.45 | EM = 71.50 | Precision = 93.52 | Recall = 93.88 | F1 = 92.90 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 12 loss 0.0258: 100% 2079/2079 [22:30<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.35699\n",
            "INFO:__main__:  global_step = 27028\n",
            "INFO:__main__:  train_loss = 0.0258\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.21 | rouge_l = 92.55 | meteor = 58.64 | EM = 72.70 | Precision = 93.79 | Recall = 93.88 | F1 = 93.09 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.20879206232543\n",
            "INFO:__main__:  ********************\n",
            "epoch 13 loss 0.0203: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.36881\n",
            "INFO:__main__:  global_step = 29107\n",
            "INFO:__main__:  train_loss = 0.0203\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.42 | rouge_l = 92.64 | meteor = 58.98 | EM = 73.20 | Precision = 93.71 | Recall = 94.19 | F1 = 93.18 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.41599658842998\n",
            "INFO:__main__:  ********************\n",
            "epoch 14 loss 0.0159: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.38473\n",
            "INFO:__main__:  global_step = 31186\n",
            "INFO:__main__:  train_loss = 0.0159\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.71 | rouge_l = 92.85 | meteor = 59.23 | EM = 74.30 | Precision = 94.06 | Recall = 94.27 | F1 = 93.41 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.7116559160565\n",
            "INFO:__main__:  ********************\n",
            "epoch 15 loss 0.0125: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.39709\n",
            "INFO:__main__:  global_step = 33265\n",
            "INFO:__main__:  train_loss = 0.0125\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.59 | rouge_l = 92.67 | meteor = 59.02 | EM = 73.70 | Precision = 93.75 | Recall = 94.19 | F1 = 93.21 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 16 loss 0.0097: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.39276\n",
            "INFO:__main__:  global_step = 35344\n",
            "INFO:__main__:  train_loss = 0.0097\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.21 | rouge_l = 92.40 | meteor = 58.43 | EM = 73.40 | Precision = 94.08 | Recall = 93.55 | F1 = 93.05 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 17 loss 0.0073: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.39937\n",
            "INFO:__main__:  global_step = 37423\n",
            "INFO:__main__:  train_loss = 0.0073\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.91 | rouge_l = 92.91 | meteor = 59.39 | EM = 74.30 | Precision = 94.09 | Recall = 94.32 | F1 = 93.50 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.91288101263694\n",
            "INFO:__main__:  ********************\n",
            "epoch 18 loss 0.0053: 100% 2079/2079 [22:29<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.40817\n",
            "INFO:__main__:  global_step = 39502\n",
            "INFO:__main__:  train_loss = 0.0053\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.93 | rouge_l = 92.91 | meteor = 59.50 | EM = 74.20 | Precision = 94.07 | Recall = 94.28 | F1 = 93.46 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.92966460878199\n",
            "INFO:__main__:  ********************\n",
            "epoch 19 loss 0.0041: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.40607\n",
            "INFO:__main__:  global_step = 41581\n",
            "INFO:__main__:  train_loss = 0.0041\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.64 | rouge_l = 92.66 | meteor = 59.05 | EM = 74.10 | Precision = 93.98 | Recall = 93.96 | F1 = 93.24 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:\n",
            "***** Running Test *****\n",
            "INFO:__main__:Test file: ../data/test/\n",
            "100% 260/260 [16:22<00:00,  3.78s/it]\n",
            "INFO:__main__:test set: bleu = 88.89 | rouge_l = 94.06 | meteor = 61.42 | EM = 76.86 | Precision = 94.78 | Recall = 95.35 | F1 = 94.49 | \n",
            "INFO:__main__:  ********************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following shell if you want to load model that has been build and run test. You don't need to run it again becuase test has been carried out in above execution."
      ],
      "metadata": {
        "id": "fKHFKQE7UbhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Test\n",
        "#!bash java_script_test.sh 0 cbQG"
      ],
      "metadata": {
        "id": "ghuwcDAaOr6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the google drive so you can copy the output to google drive. It is necessary becuase virtuan machine may be disconnected before you can copy."
      ],
      "metadata": {
        "id": "pb4nuWSdABkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WZ-mBZQOAMlP",
        "outputId": "c5e28702-fc5b-4ea3-b8c1-1a5478e52f0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip the output so that you can download all files at once"
      ],
      "metadata": {
        "id": "B37CzUi2pqiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/file.zip /content/folder_to_zip\n",
        "!zip -r /content/CbQg-ACC.zip /content/codeBERT-QG/output/CbQg-ACC\n"
      ],
      "metadata": {
        "id": "0oYlpgK_pw6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378761bf-7f58-4906-e94d-afa95d763f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/codeBERT-QG/output/CbQg-ACC/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/test_0.output (deflated 72%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/dev.gold (deflated 66%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/checkpoint-best-bleu/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/checkpoint-best-bleu/pytorch_model.bin (deflated 10%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/dev.output (deflated 66%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/checkpoint-last/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/checkpoint-last/pytorch_model.bin (deflated 10%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/test_0.gold (deflated 72%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/checkpoint-best-ppl/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/checkpoint-best-ppl/pytorch_model.bin (deflated 10%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACC/log.txt (deflated 88%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code helps you to copy your output to your goole drive"
      ],
      "metadata": {
        "id": "306nwvv_qtg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# copy it there\n",
        "!cp /content/CbQg-ACC.zip /content/drive/MyDrive/output"
      ],
      "metadata": {
        "id": "EmGUz8mwq04v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute following command if need inforamtion of system used for training."
      ],
      "metadata": {
        "id": "16oSLV0dUunh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use this command to see GPU activity while doing Deep Learning tasks, for this command 'nvidia-smi' and for above one to work, go to 'Runtime > change runtime type > Hardware Accelerator > GPU'\n",
        "!nvidia-smi\n",
        "!nvidia-smi -L\n",
        "!lscpu |grep 'Model name'\n",
        "#no.of cores each processor is having \n",
        "!lscpu | grep 'Core(s) per socket:'\n",
        "#memory that we can use\n",
        "!free -h --si | awk  '/Mem:/{print $2}'\n",
        "#hard disk space that we can use\n",
        "!df -h / | awk '{print $4}'\n",
        "#no.of sockets i.e available slots for physical processors\n",
        "!lscpu | grep 'Socket(s):'\n",
        "!lscpu | grep \"L3 cache\" \n",
        "#if it had turbo boost it would've shown Min and Max MHz also but it is only showing current frequency this means it always operates at shown frequency\n",
        "!lscpu | grep \"MHz\""
      ],
      "metadata": {
        "id": "jloTmRB9Ka16",
        "outputId": "fdc9808f-99bf-4742-f1d0-42598d03fba5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb  9 16:28:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    52W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-fe57f86b-9bd1-48d8-37d0-205ab29e13cf)\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Core(s) per socket:              6\n",
            "85G\n",
            "Avail\n",
            "143G\n",
            "Socket(s):                       1\n",
            "L3 cache:                        38.5 MiB\n",
            "CPU MHz:                         2200.204\n"
          ]
        }
      ]
    }
  ]
}
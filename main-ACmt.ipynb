{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNK1M5rLFu34yD8b9dDIeQt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljtamang/codeBERT-QG/blob/master/main-ACmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install pacakages required for successfully running this project."
      ],
      "metadata": {
        "id": "IKKRzu4LYvvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install psutil\n",
        "# !pip install h5py \n",
        "# !pip install typing-extensions \n",
        "# !pip install wheel \n",
        "!pip install blue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv_8MJCYAgMW",
        "outputId": "064fbec9-a1e2-48f3-ec0f-195c4699cf54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting blue\n",
            "  Downloading blue-0.9.1-py3-none-any.whl (10 kB)\n",
            "Collecting black==22.1.0\n",
            "  Downloading black-22.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8<5.0.0,>=3.8\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.11.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (4.4.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (2.0.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (2.6.2)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mccabe, pyflakes, pycodestyle, pathspec, mypy-extensions, click, flake8, black, blue\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed black-22.1.0 blue-0.9.1 click-8.1.3 flake8-4.0.1 mccabe-0.6.1 mypy-extensions-1.0.0 pathspec-0.11.0 pycodestyle-2.8.0 pyflakes-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the source code and data used for this project from github repository"
      ],
      "metadata": {
        "id": "f6OLvA_lTB-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ljtamang/codeBERT-QG.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l694QXfL-Uxv",
        "outputId": "6da823a6-cfe4-469b-d599-192c037f2935"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'codeBERT-QG'...\n",
            "remote: Enumerating objects: 374, done.\u001b[K\n",
            "remote: Counting objects: 100% (243/243), done.\u001b[K\n",
            "remote: Compressing objects: 100% (180/180), done.\u001b[K\n",
            "remote: Total 374 (delta 99), reused 171 (delta 56), pack-reused 131\u001b[K\n",
            "Receiving objects: 100% (374/374), 92.21 MiB | 11.25 MiB/s, done.\n",
            "Resolving deltas: 100% (168/168), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navigate inside the recently downloaded codeBERT-QG project folder"
      ],
      "metadata": {
        "id": "NUHSNiw5amwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd codeBERT-QG\n",
        "#%cd codeBERT-QG/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyA5rzWq9zsO",
        "outputId": "b0082462-3280-42b9-ed23-792eb12d130c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/codeBERT-QG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run execute java_script.sh . This will take care of everything and the project should build the model, validate and test it too."
      ],
      "metadata": {
        "id": "Ed53PSxHT04D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#when GPU 1 is available\n",
        "!bash java_script.sh 0 CbQg-ACmt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKxlAA1JD9qi",
        "outputId": "d8d55f76-55d6-4efd-8934-0055e623cc79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-10 02:08:23.635585: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n",
            "Downloading (…)lve/main/config.json: 100% 498/498 [00:00<00:00, 75.1kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:01<00:00, 644kB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:01<00:00, 413kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 150/150 [00:00<00:00, 59.2kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 9.63kB/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 499M/499M [00:02<00:00, 177MB/s]\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 0\n",
            "INFO:__main__:source_tokens: ['<s>', 'to', '_target', 'file', '</s>', 'mer', 'ges', '_source', 'xml', '_into', '_target', 'xml', '_/', '_target', 'file', '_(', '_target', 'xml', '_is', '_the', '_contents', '_of', '_target', 'file', '_)', '_.', '_returns', '_the', '_resulting', '_xml', '_if', '_it', '_still', '_needs', '_to', '_be', '_written', '_to', '_target', 'file', '_,', '_or', '_null', '_if', '_the', '_file', '_has', '_already', '_been', '_/', '_doesn', \"_'\", '_t', '_need', '_to', '_be', '_updated', '_.', '</s>']\n",
            "INFO:__main__:source_ids: 0 560 1002 21710 2 2089 5641 1300 47858 88 1002 47858 1589 1002 21710 36 1002 47858 16 5 13654 9 1002 21710 4839 479 2886 5 5203 49377 114 24 202 782 7 28 1982 7 1002 21710 2156 50 23796 114 5 2870 34 416 57 1589 630 128 326 240 7 28 4752 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'How', '_be', '_it', '_written', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 6179 28 24 1982 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 1\n",
            "INFO:__main__:source_tokens: ['<s>', 'to', '_be', '_written', '_to', '_target', 'file', '</s>', 'mer', 'ges', '_source', 'xml', '_into', '_target', 'xml', '_/', '_target', 'file', '_(', '_target', 'xml', '_is', '_the', '_contents', '_of', '_target', 'file', '_)', '_.', '_returns', '_the', '_resulting', '_xml', '_if', '_it', '_still', '_needs', '_to', '_be', '_written', '_to', '_target', 'file', '_,', '_or', '_null', '_if', '_the', '_file', '_has', '_already', '_been', '_/', '_doesn', \"_'\", '_t', '_need', '_to', '_be', '_updated', '_.', '</s>']\n",
            "INFO:__main__:source_ids: 0 560 28 1982 7 1002 21710 2 2089 5641 1300 47858 88 1002 47858 1589 1002 21710 36 1002 47858 16 5 13654 9 1002 21710 4839 479 2886 5 5203 49377 114 24 202 782 7 28 1982 7 1002 21710 2156 50 23796 114 5 2870 34 416 57 1589 630 128 326 240 7 28 4752 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_it', '_need', '_still', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 24 240 202 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 2\n",
            "INFO:__main__:source_tokens: ['<s>', 'a', '_new', '_transformer', '_object', '</s>', 'create', '_a', '_new', '_transformer', '_object', '_that', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '_.', '</s>']\n",
            "INFO:__main__:source_ids: 0 102 92 40878 7626 2 32845 10 92 40878 7626 14 14023 10 5375 9 5 1300 7 5 898 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 14023 10 5375 9 5 1300 7 5 898 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 3\n",
            "INFO:__main__:source_tokens: ['<s>', 'a', '_copy', '_of', '_the', '_source', '</s>', 'create', '_a', '_new', '_transformer', '_object', '_that', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '_.', '</s>']\n",
            "INFO:__main__:source_ids: 0 102 5375 9 5 1300 2 32845 10 92 40878 7626 14 14023 10 5375 9 5 1300 7 5 898 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_a', '_new', '_transformer', '_object', '_perform', '_to', '_the', '_result', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 10 92 40878 7626 3008 7 5 898 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 4\n",
            "INFO:__main__:source_tokens: ['<s>', 'a', '_new', '_transformer', '_object', '_that', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '</s>', 'create', '_a', '_new', '_transformer', '_object', '_that', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '_.', '</s>']\n",
            "INFO:__main__:source_ids: 0 102 92 40878 7626 14 14023 10 5375 9 5 1300 7 5 898 2 32845 10 92 40878 7626 14 14023 10 5375 9 5 1300 7 5 898 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_the', '_code', '_create', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 5 3260 1045 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:__main__:***** Running training *****\n",
            "INFO:__main__:  Num examples = 66514\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  Num epoch = 20\n",
            "epoch 0 loss 3.869: 100% 2079/2079 [22:30<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 7.4791\n",
            "INFO:__main__:  global_step = 2080\n",
            "INFO:__main__:  train_loss = 3.869\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:7.4791\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 49.50 | rouge_l = 69.14 | meteor = 30.01 | EM = 27.20 | Precision = 81.42 | Recall = 66.51 | F1 = 71.48 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:49.4992476950074\n",
            "INFO:__main__:  ********************\n",
            "epoch 1 loss 1.1835: 100% 2079/2079 [22:27<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.75723\n",
            "INFO:__main__:  global_step = 4159\n",
            "INFO:__main__:  train_loss = 1.1835\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.75723\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 74.86 | rouge_l = 86.01 | meteor = 48.10 | EM = 53.10 | Precision = 90.96 | Recall = 86.23 | F1 = 87.09 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:74.8570558148134\n",
            "INFO:__main__:  ********************\n",
            "epoch 2 loss 0.4514: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.41972\n",
            "INFO:__main__:  global_step = 6238\n",
            "INFO:__main__:  train_loss = 0.4514\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.41972\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 80.74 | rouge_l = 89.62 | meteor = 53.58 | EM = 62.10 | Precision = 92.59 | Recall = 90.49 | F1 = 90.50 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:80.74468695052231\n",
            "INFO:__main__:  ********************\n",
            "epoch 3 loss 0.2629: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.34373\n",
            "INFO:__main__:  global_step = 8317\n",
            "INFO:__main__:  train_loss = 0.2629\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.34373\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 83.05 | rouge_l = 90.87 | meteor = 55.87 | EM = 66.20 | Precision = 92.76 | Recall = 91.88 | F1 = 91.44 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:83.04566419428974\n",
            "INFO:__main__:  ********************\n",
            "epoch 4 loss 0.1816: 100% 2079/2079 [22:27<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.32848\n",
            "INFO:__main__:  global_step = 10396\n",
            "INFO:__main__:  train_loss = 0.1816\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.32848\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 83.73 | rouge_l = 91.09 | meteor = 56.11 | EM = 68.00 | Precision = 93.45 | Recall = 91.93 | F1 = 91.85 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:83.73355627988416\n",
            "INFO:__main__:  ********************\n",
            "epoch 5 loss 0.1345: 100% 2079/2079 [22:27<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.31707\n",
            "INFO:__main__:  global_step = 12475\n",
            "INFO:__main__:  train_loss = 0.1345\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.31707\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 84.99 | rouge_l = 91.94 | meteor = 57.66 | EM = 70.70 | Precision = 93.30 | Recall = 93.25 | F1 = 92.45 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:84.98870041334696\n",
            "INFO:__main__:  ********************\n",
            "epoch 6 loss 0.1037: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.34827\n",
            "INFO:__main__:  global_step = 14554\n",
            "INFO:__main__:  train_loss = 0.1037\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 85.48 | rouge_l = 92.05 | meteor = 57.78 | EM = 71.50 | Precision = 93.63 | Recall = 93.22 | F1 = 92.68 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:85.48394289094351\n",
            "INFO:__main__:  ********************\n",
            "epoch 7 loss 0.0811: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.31742\n",
            "INFO:__main__:  global_step = 16633\n",
            "INFO:__main__:  train_loss = 0.0811\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 85.92 | rouge_l = 92.38 | meteor = 58.24 | EM = 71.30 | Precision = 93.67 | Recall = 93.68 | F1 = 92.96 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:85.92087019432928\n",
            "INFO:__main__:  ********************\n",
            "epoch 8 loss 0.0624: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.3153\n",
            "INFO:__main__:  global_step = 18712\n",
            "INFO:__main__:  train_loss = 0.0624\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.3153\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.57 | rouge_l = 92.69 | meteor = 59.44 | EM = 73.40 | Precision = 93.94 | Recall = 94.11 | F1 = 93.29 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.56659392726438\n",
            "INFO:__main__:  ********************\n",
            "epoch 9 loss 0.0498: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.32193\n",
            "INFO:__main__:  global_step = 20791\n",
            "INFO:__main__:  train_loss = 0.0498\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.53 | rouge_l = 92.57 | meteor = 59.07 | EM = 73.30 | Precision = 93.99 | Recall = 93.71 | F1 = 93.17 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 10 loss 0.0391: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.32926\n",
            "INFO:__main__:  global_step = 22870\n",
            "INFO:__main__:  train_loss = 0.0391\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 85.96 | rouge_l = 92.39 | meteor = 58.74 | EM = 72.00 | Precision = 93.58 | Recall = 93.75 | F1 = 92.95 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 11 loss 0.0312: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.34325\n",
            "INFO:__main__:  global_step = 24949\n",
            "INFO:__main__:  train_loss = 0.0312\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.57 | rouge_l = 92.61 | meteor = 58.80 | EM = 73.60 | Precision = 93.95 | Recall = 93.86 | F1 = 93.17 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 12 loss 0.0245: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.34918\n",
            "INFO:__main__:  global_step = 27028\n",
            "INFO:__main__:  train_loss = 0.0245\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.52 | rouge_l = 92.66 | meteor = 59.08 | EM = 73.20 | Precision = 94.02 | Recall = 94.02 | F1 = 93.29 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 13 loss 0.02: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.35184\n",
            "INFO:__main__:  global_step = 29107\n",
            "INFO:__main__:  train_loss = 0.02\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.52 | rouge_l = 92.64 | meteor = 58.93 | EM = 72.80 | Precision = 93.82 | Recall = 93.99 | F1 = 93.21 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 14 loss 0.0158: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.36475\n",
            "INFO:__main__:  global_step = 31186\n",
            "INFO:__main__:  train_loss = 0.0158\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.65 | rouge_l = 92.69 | meteor = 59.26 | EM = 73.50 | Precision = 93.97 | Recall = 93.82 | F1 = 93.21 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.64528766958756\n",
            "INFO:__main__:  ********************\n",
            "epoch 15 loss 0.0125: 100% 2079/2079 [22:27<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.37291\n",
            "INFO:__main__:  global_step = 33265\n",
            "INFO:__main__:  train_loss = 0.0125\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.31 | rouge_l = 92.47 | meteor = 59.17 | EM = 73.00 | Precision = 93.75 | Recall = 93.79 | F1 = 93.03 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 16 loss 0.0098: 100% 2079/2079 [22:27<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.3707\n",
            "INFO:__main__:  global_step = 35344\n",
            "INFO:__main__:  train_loss = 0.0098\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 87.03 | rouge_l = 92.92 | meteor = 59.61 | EM = 74.10 | Precision = 94.19 | Recall = 94.08 | F1 = 93.46 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:87.02606910618627\n",
            "INFO:__main__:  ********************\n",
            "epoch 17 loss 0.0075: 100% 2079/2079 [22:27<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.37527\n",
            "INFO:__main__:  global_step = 37423\n",
            "INFO:__main__:  train_loss = 0.0075\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.77 | rouge_l = 92.76 | meteor = 59.52 | EM = 74.20 | Precision = 94.07 | Recall = 93.95 | F1 = 93.30 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 18 loss 0.0056: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.38665\n",
            "INFO:__main__:  global_step = 39502\n",
            "INFO:__main__:  train_loss = 0.0056\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.80 | rouge_l = 92.75 | meteor = 59.52 | EM = 74.00 | Precision = 94.04 | Recall = 93.95 | F1 = 93.27 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 19 loss 0.0046: 100% 2079/2079 [22:28<00:00,  1.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.38891\n",
            "INFO:__main__:  global_step = 41581\n",
            "INFO:__main__:  train_loss = 0.0046\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.90 | rouge_l = 92.85 | meteor = 59.61 | EM = 74.40 | Precision = 94.09 | Recall = 94.09 | F1 = 93.38 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:\n",
            "***** Running Test *****\n",
            "INFO:__main__:Test file: ../data/test/\n",
            "100% 260/260 [16:33<00:00,  3.82s/it]\n",
            "INFO:__main__:test set: bleu = 89.12 | rouge_l = 94.20 | meteor = 61.62 | EM = 77.05 | Precision = 94.96 | Recall = 95.47 | F1 = 94.64 | \n",
            "INFO:__main__:  ********************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following shell if you want to load model that has been build and run test. You don't need to run it again becuase test has been carried out in above execution."
      ],
      "metadata": {
        "id": "fKHFKQE7UbhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Test\n",
        "#!bash java_script_test.sh 0 cbQG"
      ],
      "metadata": {
        "id": "ghuwcDAaOr6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the google drive so you can copy the output to google drive. It is necessary becuase virtuan machine may be disconnected before you can copy."
      ],
      "metadata": {
        "id": "pb4nuWSdABkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WZ-mBZQOAMlP",
        "outputId": "12c597aa-6e1d-40d3-c419-a8bb70e58eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip the output so that you can download all files at once"
      ],
      "metadata": {
        "id": "B37CzUi2pqiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/file.zip /content/folder_to_zip\n",
        "!zip -r /content/CbQg-ACmt.zip /content/codeBERT-QG/output/CbQg-ACmt\n"
      ],
      "metadata": {
        "id": "0oYlpgK_pw6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e42d58-d141-458e-8612-11fe1a9341e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/dev.output (deflated 66%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/checkpoint-best-ppl/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/checkpoint-best-ppl/pytorch_model.bin (deflated 10%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/test_0.output (deflated 72%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/log.txt (deflated 89%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/test_0.gold (deflated 72%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/checkpoint-best-bleu/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/checkpoint-best-bleu/pytorch_model.bin (deflated 10%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/checkpoint-last/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/checkpoint-last/pytorch_model.bin (deflated 10%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-ACmt/dev.gold (deflated 66%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code helps you to copy your output to your goole drive"
      ],
      "metadata": {
        "id": "306nwvv_qtg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# copy it there\n",
        "!cp /content/CbQg-ACmt.zip /content/drive/MyDrive/output"
      ],
      "metadata": {
        "id": "EmGUz8mwq04v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute following command if need inforamtion of system used for training."
      ],
      "metadata": {
        "id": "16oSLV0dUunh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use this command to see GPU activity while doing Deep Learning tasks, for this command 'nvidia-smi' and for above one to work, go to 'Runtime > change runtime type > Hardware Accelerator > GPU'\n",
        "!nvidia-smi\n",
        "!nvidia-smi -L\n",
        "!lscpu |grep 'Model name'\n",
        "#no.of cores each processor is having \n",
        "!lscpu | grep 'Core(s) per socket:'\n",
        "#memory that we can use\n",
        "!free -h --si | awk  '/Mem:/{print $2}'\n",
        "#hard disk space that we can use\n",
        "!df -h / | awk '{print $4}'\n",
        "#no.of sockets i.e available slots for physical processors\n",
        "!lscpu | grep 'Socket(s):'\n",
        "!lscpu | grep \"L3 cache\" \n",
        "#if it had turbo boost it would've shown Min and Max MHz also but it is only showing current frequency this means it always operates at shown frequency\n",
        "!lscpu | grep \"MHz\""
      ],
      "metadata": {
        "id": "jloTmRB9Ka16",
        "outputId": "fd9d99d1-e673-4fa4-81a1-ebbadb93b8bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 10 10:59:23 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    49W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-7f259069-ea49-f29a-5743-3cff0a147f5c)\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Core(s) per socket:              6\n",
            "85G\n",
            "Avail\n",
            "137G\n",
            "Socket(s):                       1\n",
            "L3 cache:                        38.5 MiB\n",
            "CPU MHz:                         2200.210\n"
          ]
        }
      ]
    }
  ]
}
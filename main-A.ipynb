{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOOoajC//pf3V7JPgbPTY/B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljtamang/codeBERT-QG/blob/master/main-A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install pacakages required for successfully running this project."
      ],
      "metadata": {
        "id": "IKKRzu4LYvvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install psutil\n",
        "# !pip install h5py \n",
        "# !pip install typing-extensions \n",
        "# !pip install wheel \n",
        "!pip install blue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv_8MJCYAgMW",
        "outputId": "ca0df290-d771-4b38-e1ac-25aca88825b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting blue\n",
            "  Downloading blue-0.9.1-py3-none-any.whl (10 kB)\n",
            "Collecting flake8<5.0.0,>=3.8\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==22.1.0\n",
            "  Downloading black-22.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (4.4.0)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (3.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (2.0.1)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.11.0-py3-none-any.whl (29 kB)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mccabe, pyflakes, pycodestyle, pathspec, mypy-extensions, click, flake8, black, blue\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed black-22.1.0 blue-0.9.1 click-8.1.3 flake8-4.0.1 mccabe-0.6.1 mypy-extensions-1.0.0 pathspec-0.11.0 pycodestyle-2.8.0 pyflakes-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the source code and data used for this project from github repository"
      ],
      "metadata": {
        "id": "f6OLvA_lTB-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ljtamang/codeBERT-QG.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l694QXfL-Uxv",
        "outputId": "a5074a76-0d56-42e0-d2be-ab6ba73492a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'codeBERT-QG'...\n",
            "remote: Enumerating objects: 430, done.\u001b[K\n",
            "remote: Counting objects: 100% (299/299), done.\u001b[K\n",
            "remote: Compressing objects: 100% (230/230), done.\u001b[K\n",
            "remote: Total 430 (delta 129), reused 193 (delta 62), pack-reused 131\u001b[K\n",
            "Receiving objects: 100% (430/430), 106.60 MiB | 16.31 MiB/s, done.\n",
            "Resolving deltas: 100% (198/198), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navigate inside the recently downloaded codeBERT-QG project folder"
      ],
      "metadata": {
        "id": "NUHSNiw5amwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd codeBERT-QG\n",
        "#%cd codeBERT-QG/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyA5rzWq9zsO",
        "outputId": "1c63542d-3270-4179-bbe9-f6d4bd6239d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/codeBERT-QG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run execute java_script.sh . This will take care of everything and the project should build the model, validate and test it too."
      ],
      "metadata": {
        "id": "Ed53PSxHT04D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#when GPU 1 is available\n",
        "!bash java_script.sh 0 CbQg-A\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKxlAA1JD9qi",
        "outputId": "bcfb5a70-3b5d-4e2c-c858-80c827b72429"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-15 00:49:55.193549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-15 00:49:55.347765: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-02-15 00:49:56.103038: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-15 00:49:56.103125: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-15 00:49:56.103143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n",
            "Downloading (…)lve/main/config.json: 100% 498/498 [00:00<00:00, 75.1kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:00<00:00, 6.25MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 3.26MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 150/150 [00:00<00:00, 60.6kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 10.1kB/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 499M/499M [00:07<00:00, 67.8MB/s]\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 0\n",
            "INFO:__main__:source_tokens: ['<s>', 'to', '_target', 'file', '</s>']\n",
            "INFO:__main__:source_ids: 0 560 1002 21710 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'How', '_be', '_it', '_written', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 6179 28 24 1982 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 1\n",
            "INFO:__main__:source_tokens: ['<s>', 'to', '_be', '_written', '_to', '_target', 'file', '</s>']\n",
            "INFO:__main__:source_ids: 0 560 28 1982 7 1002 21710 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_it', '_need', '_still', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 24 240 202 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 2\n",
            "INFO:__main__:source_tokens: ['<s>', 'a', '_new', '_transformer', '_object', '</s>']\n",
            "INFO:__main__:source_ids: 0 102 92 40878 7626 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 14023 10 5375 9 5 1300 7 5 898 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 3\n",
            "INFO:__main__:source_tokens: ['<s>', 'a', '_copy', '_of', '_the', '_source', '</s>']\n",
            "INFO:__main__:source_ids: 0 102 5375 9 5 1300 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_a', '_new', '_transformer', '_object', '_perform', '_to', '_the', '_result', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 10 92 40878 7626 3008 7 5 898 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 4\n",
            "INFO:__main__:source_tokens: ['<s>', 'a', '_new', '_transformer', '_object', '_that', '_performs', '_a', '_copy', '_of', '_the', '_source', '_to', '_the', '_result', '</s>']\n",
            "INFO:__main__:source_ids: 0 102 92 40878 7626 14 14023 10 5375 9 5 1300 7 5 898 2 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_the', '_code', '_create', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 5 3260 1045 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:__main__:***** Running training *****\n",
            "INFO:__main__:  Num examples = 66514\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  Num epoch = 20\n",
            "epoch 0 loss 4.3011: 100% 2079/2079 [04:05<00:00,  8.48it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 27.05761\n",
            "INFO:__main__:  global_step = 2080\n",
            "INFO:__main__:  train_loss = 4.3011\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:27.05761\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 32.22 | rouge_l = 49.77 | meteor = 17.61 | EM = 7.20 | Precision = 58.94 | Recall = 47.22 | F1 = 50.96 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:32.22285866147072\n",
            "INFO:__main__:  ********************\n",
            "epoch 1 loss 3.118: 100% 2079/2079 [04:03<00:00,  8.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 19.4809\n",
            "INFO:__main__:  global_step = 4159\n",
            "INFO:__main__:  train_loss = 3.118\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:19.4809\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 32.43 | rouge_l = 49.63 | meteor = 17.88 | EM = 8.10 | Precision = 58.35 | Recall = 47.72 | F1 = 50.97 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:32.43364441467761\n",
            "INFO:__main__:  ********************\n",
            "epoch 2 loss 2.7792: 100% 2079/2079 [04:03<00:00,  8.56it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 16.00892\n",
            "INFO:__main__:  global_step = 6238\n",
            "INFO:__main__:  train_loss = 2.7792\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:16.00892\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 33.28 | rouge_l = 50.28 | meteor = 18.33 | EM = 9.80 | Precision = 59.09 | Recall = 48.40 | F1 = 51.64 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:33.281300906704125\n",
            "INFO:__main__:  ********************\n",
            "epoch 3 loss 2.4897: 100% 2079/2079 [04:02<00:00,  8.56it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 14.48454\n",
            "INFO:__main__:  global_step = 8317\n",
            "INFO:__main__:  train_loss = 2.4897\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:14.48454\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 33.64 | rouge_l = 50.87 | meteor = 18.64 | EM = 10.90 | Precision = 59.29 | Recall = 48.84 | F1 = 52.04 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:33.63672077952462\n",
            "INFO:__main__:  ********************\n",
            "epoch 4 loss 2.24: 100% 2079/2079 [04:02<00:00,  8.56it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 13.74907\n",
            "INFO:__main__:  global_step = 10396\n",
            "INFO:__main__:  train_loss = 2.24\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:13.74907\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 34.96 | rouge_l = 51.66 | meteor = 19.10 | EM = 12.10 | Precision = 60.33 | Recall = 49.39 | F1 = 52.79 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:34.963053517857404\n",
            "INFO:__main__:  ********************\n",
            "epoch 5 loss 2.015: 100% 2079/2079 [04:02<00:00,  8.57it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 13.35403\n",
            "INFO:__main__:  global_step = 12475\n",
            "INFO:__main__:  train_loss = 2.015\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:13.35403\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 35.60 | rouge_l = 52.15 | meteor = 19.58 | EM = 12.70 | Precision = 60.78 | Recall = 50.00 | F1 = 53.34 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:35.59592122181222\n",
            "INFO:__main__:  ********************\n",
            "epoch 6 loss 1.8093: 100% 2079/2079 [04:02<00:00,  8.56it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 13.28346\n",
            "INFO:__main__:  global_step = 14554\n",
            "INFO:__main__:  train_loss = 1.8093\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:13.28346\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 35.44 | rouge_l = 51.70 | meteor = 19.70 | EM = 13.30 | Precision = 60.04 | Recall = 49.80 | F1 = 52.90 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 7 loss 1.6185: 100% 2079/2079 [04:02<00:00,  8.56it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 13.39179\n",
            "INFO:__main__:  global_step = 16633\n",
            "INFO:__main__:  train_loss = 1.6185\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 36.91 | rouge_l = 53.10 | meteor = 20.37 | EM = 14.10 | Precision = 60.69 | Recall = 51.43 | F1 = 54.22 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:36.91299359377529\n",
            "INFO:__main__:  ********************\n",
            "epoch 8 loss 1.4464: 100% 2079/2079 [04:02<00:00,  8.56it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 13.63733\n",
            "INFO:__main__:  global_step = 18712\n",
            "INFO:__main__:  train_loss = 1.4464\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 37.61 | rouge_l = 53.35 | meteor = 20.84 | EM = 15.50 | Precision = 60.88 | Recall = 51.62 | F1 = 54.38 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:37.606576605466266\n",
            "INFO:__main__:  ********************\n",
            "epoch 9 loss 1.2892: 100% 2079/2079 [04:02<00:00,  8.56it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 14.09362\n",
            "INFO:__main__:  global_step = 20791\n",
            "INFO:__main__:  train_loss = 1.2892\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 38.27 | rouge_l = 53.70 | meteor = 21.18 | EM = 16.10 | Precision = 60.55 | Recall = 52.22 | F1 = 54.66 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:38.27362056585072\n",
            "INFO:__main__:  ********************\n",
            "epoch 10 loss 1.1494: 100% 2079/2079 [04:02<00:00,  8.56it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 14.66198\n",
            "INFO:__main__:  global_step = 22870\n",
            "INFO:__main__:  train_loss = 1.1494\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 38.44 | rouge_l = 53.70 | meteor = 21.12 | EM = 16.80 | Precision = 60.47 | Recall = 52.25 | F1 = 54.60 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:38.437142819109916\n",
            "INFO:__main__:  ********************\n",
            "epoch 11 loss 1.0255: 100% 2079/2079 [04:02<00:00,  8.56it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 15.1344\n",
            "INFO:__main__:  global_step = 24949\n",
            "INFO:__main__:  train_loss = 1.0255\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 38.54 | rouge_l = 54.03 | meteor = 21.46 | EM = 16.90 | Precision = 61.02 | Recall = 52.58 | F1 = 55.02 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:38.54288708080873\n",
            "INFO:__main__:  ********************\n",
            "epoch 12 loss 0.9192: 100% 2079/2079 [04:03<00:00,  8.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 15.67237\n",
            "INFO:__main__:  global_step = 27028\n",
            "INFO:__main__:  train_loss = 0.9192\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 38.68 | rouge_l = 54.10 | meteor = 21.67 | EM = 17.20 | Precision = 60.53 | Recall = 52.99 | F1 = 54.99 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:38.6780513967666\n",
            "INFO:__main__:  ********************\n",
            "epoch 13 loss 0.8242: 100% 2079/2079 [04:03<00:00,  8.53it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 16.42386\n",
            "INFO:__main__:  global_step = 29107\n",
            "INFO:__main__:  train_loss = 0.8242\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 39.18 | rouge_l = 54.21 | meteor = 21.95 | EM = 17.40 | Precision = 60.42 | Recall = 53.18 | F1 = 55.12 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:39.175215716909825\n",
            "INFO:__main__:  ********************\n",
            "epoch 14 loss 0.7448: 100% 2079/2079 [04:03<00:00,  8.54it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 16.87676\n",
            "INFO:__main__:  global_step = 31186\n",
            "INFO:__main__:  train_loss = 0.7448\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 39.50 | rouge_l = 54.55 | meteor = 22.32 | EM = 18.10 | Precision = 59.91 | Recall = 54.14 | F1 = 55.32 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:39.50272251252323\n",
            "INFO:__main__:  ********************\n",
            "epoch 15 loss 0.6789: 100% 2079/2079 [04:03<00:00,  8.53it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 17.41672\n",
            "INFO:__main__:  global_step = 33265\n",
            "INFO:__main__:  train_loss = 0.6789\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 39.87 | rouge_l = 54.74 | meteor = 22.56 | EM = 18.50 | Precision = 60.33 | Recall = 54.03 | F1 = 55.57 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:39.87316191495445\n",
            "INFO:__main__:  ********************\n",
            "epoch 16 loss 0.6218: 100% 2079/2079 [04:03<00:00,  8.53it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 17.9867\n",
            "INFO:__main__:  global_step = 35344\n",
            "INFO:__main__:  train_loss = 0.6218\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 39.92 | rouge_l = 54.98 | meteor = 22.47 | EM = 18.70 | Precision = 60.81 | Recall = 54.25 | F1 = 55.92 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:39.91533577666241\n",
            "INFO:__main__:  ********************\n",
            "epoch 17 loss 0.5746: 100% 2079/2079 [04:04<00:00,  8.52it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 18.3636\n",
            "INFO:__main__:  global_step = 37423\n",
            "INFO:__main__:  train_loss = 0.5746\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 40.09 | rouge_l = 55.03 | meteor = 22.78 | EM = 19.10 | Precision = 60.41 | Recall = 54.62 | F1 = 55.88 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:40.087915843495345\n",
            "INFO:__main__:  ********************\n",
            "epoch 18 loss 0.5395: 100% 2079/2079 [04:04<00:00,  8.51it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 18.65079\n",
            "INFO:__main__:  global_step = 39502\n",
            "INFO:__main__:  train_loss = 0.5395\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 40.52 | rouge_l = 55.17 | meteor = 22.91 | EM = 19.90 | Precision = 60.51 | Recall = 54.64 | F1 = 55.99 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:40.51828085482278\n",
            "INFO:__main__:  ********************\n",
            "epoch 19 loss 0.5142: 100% 2079/2079 [04:04<00:00,  8.51it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 8314\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 18.81914\n",
            "INFO:__main__:  global_step = 41581\n",
            "INFO:__main__:  train_loss = 0.5142\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 40.33 | rouge_l = 55.21 | meteor = 22.90 | EM = 19.50 | Precision = 60.39 | Recall = 54.89 | F1 = 56.03 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:\n",
            "***** Running Test *****\n",
            "INFO:__main__:Test file: ../data/test/\n",
            "100% 260/260 [16:28<00:00,  3.80s/it]\n",
            "INFO:__main__:test set: bleu = 39.86 | rouge_l = 54.58 | meteor = 22.37 | EM = 19.61 | Precision = 60.08 | Recall = 54.05 | F1 = 55.37 | \n",
            "INFO:__main__:  ********************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following shell if you want to load model that has been build and run test. You don't need to run it again becuase test has been carried out in above execution."
      ],
      "metadata": {
        "id": "fKHFKQE7UbhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Test\n",
        "#!bash java_script_test.sh 0 cbQG"
      ],
      "metadata": {
        "id": "ghuwcDAaOr6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the google drive so you can copy the output to google drive. It is necessary becuase virtuan machine may be disconnected before you can copy."
      ],
      "metadata": {
        "id": "pb4nuWSdABkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WZ-mBZQOAMlP",
        "outputId": "8bf635c6-3ecc-420a-fb3e-c75af6e162f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip the output so that you can download all files at once"
      ],
      "metadata": {
        "id": "B37CzUi2pqiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/file.zip /content/folder_to_zip\n",
        "!zip -r /content/CbQg-A.zip /content/codeBERT-QG/output/CbQg-A\n"
      ],
      "metadata": {
        "id": "0oYlpgK_pw6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f82673-daec-4668-c91c-32e6ff4eefae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/codeBERT-QG/output/CbQg-A/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/checkpoint-last/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/checkpoint-last/pytorch_model.bin (deflated 10%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/checkpoint-best-ppl/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/checkpoint-best-ppl/pytorch_model.bin (deflated 10%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/dev.output (deflated 71%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/test_0.gold (deflated 72%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/checkpoint-best-bleu/ (stored 0%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/checkpoint-best-bleu/pytorch_model.bin (deflated 10%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/test_0.output (deflated 76%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/log.txt (deflated 85%)\n",
            "  adding: content/codeBERT-QG/output/CbQg-A/dev.gold (deflated 66%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code helps you to copy your output to your goole drive"
      ],
      "metadata": {
        "id": "306nwvv_qtg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# copy it there\n",
        "!cp /content/CbQg-A.zip /content/drive/MyDrive/output"
      ],
      "metadata": {
        "id": "EmGUz8mwq04v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute following command if need inforamtion of system used for training."
      ],
      "metadata": {
        "id": "16oSLV0dUunh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use this command to see GPU activity while doing Deep Learning tasks, for this command 'nvidia-smi' and for above one to work, go to 'Runtime > change runtime type > Hardware Accelerator > GPU'\n",
        "!nvidia-smi\n",
        "!nvidia-smi -L\n",
        "!lscpu |grep 'Model name'\n",
        "#no.of cores each processor is having \n",
        "!lscpu | grep 'Core(s) per socket:'\n",
        "#memory that we can use\n",
        "!free -h --si | awk  '/Mem:/{print $2}'\n",
        "#hard disk space that we can use\n",
        "!df -h / | awk '{print $4}'\n",
        "#no.of sockets i.e available slots for physical processors\n",
        "!lscpu | grep 'Socket(s):'\n",
        "!lscpu | grep \"L3 cache\" \n",
        "#if it had turbo boost it would've shown Min and Max MHz also but it is only showing current frequency this means it always operates at shown frequency\n",
        "!lscpu | grep \"MHz\""
      ],
      "metadata": {
        "id": "jloTmRB9Ka16",
        "outputId": "5f787a60-e204-4add-9c1f-3a90d6b30aff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb 15 03:14:49 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    49W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-a286925b-0762-c678-4da3-61c4208c0c11)\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Core(s) per socket:              6\n",
            "85G\n",
            "Avail\n",
            "136G\n",
            "Socket(s):                       1\n",
            "L3 cache:                        38.5 MiB\n",
            "CPU MHz:                         2200.206\n"
          ]
        }
      ]
    }
  ]
}
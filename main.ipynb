{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNrmNK6tC4LoAe4E8JdXacH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljtamang/codeBERT-QG/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install pacakages required for successfully running this project."
      ],
      "metadata": {
        "id": "IKKRzu4LYvvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install psutil\n",
        "# !pip install h5py \n",
        "# !pip install typing-extensions \n",
        "# !pip install wheel \n",
        "!pip install blue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv_8MJCYAgMW",
        "outputId": "7e2ecf6a-55de-4be5-90a0-1c543b1b2ee1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting blue\n",
            "  Downloading blue-0.9.1-py3-none-any.whl (10 kB)\n",
            "Collecting black==22.1.0\n",
            "  Downloading black-22.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8<5.0.0,>=3.8\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (4.4.0)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.11.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (2.0.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black==22.1.0->blue) (2.6.2)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: mccabe, pyflakes, pycodestyle, pathspec, mypy-extensions, click, flake8, black, blue\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed black-22.1.0 blue-0.9.1 click-8.1.3 flake8-4.0.1 mccabe-0.6.1 mypy-extensions-1.0.0 pathspec-0.11.0 pycodestyle-2.8.0 pyflakes-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the source code and data used for this project from github repository"
      ],
      "metadata": {
        "id": "f6OLvA_lTB-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ljtamang/codeBERT-QG.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l694QXfL-Uxv",
        "outputId": "0f04f617-fd64-441d-fafd-d510b4fa291f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'codeBERT-QG'...\n",
            "remote: Enumerating objects: 254, done.\u001b[K\n",
            "remote: Counting objects: 100% (194/194), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 254 (delta 100), reused 153 (delta 76), pack-reused 60\u001b[K\n",
            "Receiving objects: 100% (254/254), 80.09 MiB | 33.57 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navigate inside the recently downloaded codeBERT-QG project folder"
      ],
      "metadata": {
        "id": "NUHSNiw5amwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd codeBERT-QG\n",
        "#%cd codeBERT-QG/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyA5rzWq9zsO",
        "outputId": "a00e086a-057b-47de-e3d6-d76cdbb40eee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/codeBERT-QG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run execute java_script.sh . This will take care of everything and the project should build the model, validate and test it too."
      ],
      "metadata": {
        "id": "Ed53PSxHT04D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#when GPU 1 is available\n",
        "!bash java_script.sh 0 model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKxlAA1JD9qi",
        "outputId": "d8a8d767-7390-4e6a-9e18-24595178a6fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-06 01:26:08.250426: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 0\n",
            "INFO:__main__:source_tokens: ['<s>', 'the', '_number', '_of', '_child', '_layers', '_in', '_this', '_group', '</s>', 'return', 's', '_the', '_number', '_of', '_child', '_layers', '_in', '_this', '_group', '_.', '</s>', 'public', '_int', '_children', '_(', '_)', '_{', '_return', '_children', '_.', '_size', '_(', '_)', '_;', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 627 346 9 920 13171 11 42 333 2 30921 29 5 346 9 920 13171 11 42 333 479 2 15110 6979 408 36 4839 25522 671 408 479 1836 36 4839 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_the', '_code', '_return', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 5 3260 671 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 1\n",
            "INFO:__main__:source_tokens: ['<s>', 'the', '_specified', '_sequence', '_of', '_char', '_values', '</s>', 'return', 's', '_true', '_if', '_and', '_only', '_if', '_this', '_string', '_contains', '_the', '_specified', '_sequence', '_of', '_char', '_values', '_.', '</s>', 'public', '_boolean', '_contains', '_(', '_String', '_str', '_)', '_{', '_for', '_(', '_String', '_text', '_:', '_logs', '_)', '_if', '_(', '_text', '_!=', '_null', '_&&', '_text', '_.', '_contains', '_(', '_str', '_)', '_)', '_return', '_BO', 'OL', '_;', '_return', '_BO', 'OL', '_;', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 627 17966 13931 9 16224 3266 2 30921 29 1528 114 8 129 114 42 6755 6308 5 17966 13931 9 16224 3266 479 2 15110 49378 6308 36 26602 7031 4839 25522 13 36 26602 2788 4832 24113 4839 114 36 2788 49333 23796 48200 2788 479 6308 36 7031 4839 4839 671 9963 3384 25606 671 9963 3384 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'What', '_does', '_this', '_string', '_contain', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 2264 473 42 6755 5585 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 2\n",
            "INFO:__main__:source_tokens: ['<s>', 'within', '_the', '_parameter', '_storage', '_algorithm', '</s>', 'checks', '_whether', '_or', '_not', '_the', '_method', '_may', '_be', '_called', '_within', '_the', '_parameter', '_storage', '_algorithm', '_.', '</s>', 'private', '_boolean', '_is', '_Accept', 'ed', '_Method', '_(', '_String', '_method', '_)', '_{', '_for', '_(', '_String', '_allowed', '_:', '_ALL', 'OW', 'ED', '_M', 'ETHOD', 'S', '_)', '_{', '_if', '_(', '_allowed', '_.', '_equals', '_(', '_method', '_)', '_)', '_{', '_return', '_BO', 'OL', '_;', '_}', '_}', '_return', '_BO', 'OL', '_;', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 34451 5 43797 3521 17194 2 28511 549 50 45 5 5448 189 28 373 624 5 43797 3521 17194 479 2 22891 49378 16 29081 196 16410 36 26602 5448 4839 25522 13 36 26602 1220 4832 12389 4581 1691 256 40086 104 4839 25522 114 36 1220 479 27601 36 5448 4839 4839 25522 671 9963 3384 25606 35524 35524 671 9963 3384 25606 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'Where', '_may', '_the', '_method', '_be', '_called', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 13841 189 5 5448 28 373 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 3\n",
            "INFO:__main__:source_tokens: ['<s>', 'before', '_copying', '_them', '_to', '_b', '</s>', 'att', 'empt', 's', '_to', '_read', '_len', '_bytes', '_into', '_byte', '_array', '_b', '_at', '_offset', '_off', '_.', '_returns', '_the', '_number', '_of', '_bytes', '_read', '_,', '_or', '_-', '_1', '_if', '_the', '_end', '_of', '_stream', '_/', '_block', '_data', '_has', '_been', '_reached', '_.', '_if', '_copy', '_is', '_true', '_,', '_reads', '_values', '_into', '_an', '_intermediate', '_buffer', '_before', '_copying', '_them', '_to', '_b', '_(', '_to', '_avoid', '_exposing', '_a', '_reference', '_to', '_b', '_)', '_.', '</s>', 'int', '_read', '_(', '_byte', '_[', '_]', '_b', '_,', '_int', '_off', '_,', '_int', '_len', '_,', '_boolean', '_copy', '_)', '_throws', '_IO', '_Exception', '_{', '_if', '_(', '_len', '_==', '_NUM', '_)', '_{', '_return', '_NUM', '_;', '_}', '_else', '_if', '_(', '_bl', 'km', 'ode', '_)', '_{', '_if', '_(', '_pos', '_==', '_end', '_)', '_{', '_refill', '_(', '_)', '_;', '_}', '_if', '_(', '_end', '_<', '_NUM', '_)', '_{', '_return', '_-', '_NUM', '_;', '_}', '_int', '_n', 'read', '_=', '_Math', '_.', '_min', '_(', '_len', '_,', '_end', '_-', '_pos', '_)', '_;', '_System', '_.', '_array', 'copy', '_(', '_buf', '_,', '_pos', '_,', '_b', '_,', '_off', '_,', '_n', 'read', '_)', '_;', '_pos', '_+=', '_n', 'read', '_;', '_return', '_n', 'read', '_;', '_}', '_else', '_if', '_(', '_copy', '_)', '_{', '_int', '_n', 'read', '_=', '_in', '_.', '_read', '_(', '_buf', '_,', '_NUM', '_,', '_Math', '_.', '_min', '_(', '_len', '_,', '_MAX', '_BL', 'OCK', '_S', 'IZE', '_)', '_)', '_;', '_if', '_(', '_n', 'read', '_>', '_NUM', '_)', '_{', '_System', '_.', '_array', 'copy', '_(', '_buf', '_,', '_NUM', '_,', '_b', '_,', '_off', '_,', '_n', 'read', '_)', '_;', '_}', '_return', '_n', 'read', '_;', '_}', '_else', '_{', '_return', '_in', '_.', '_read', '_(', '_b', '_,', '_off', '_,', '_len', '_)', '_;', '_}', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 23033 34236 106 7 741 2 2611 15318 29 7 1166 25528 46487 88 47893 8932 741 23 6147 160 479 2886 5 346 9 46487 1166 2156 50 111 112 114 5 253 9 4615 1589 1803 414 34 57 1348 479 114 5375 16 1528 2156 7005 3266 88 41 21398 21944 137 34236 106 7 741 36 7 1877 17902 10 5135 7 741 4839 479 2 2544 1166 36 47893 646 27779 741 2156 6979 160 2156 6979 25528 2156 49378 5375 4839 6989 38266 47617 25522 114 36 25528 45994 34300 4839 25522 671 34300 25606 35524 1493 114 36 3089 7203 4636 4839 25522 114 36 8593 45994 253 4839 25522 40453 36 4839 25606 35524 114 36 253 28696 34300 4839 25522 671 111 34300 25606 35524 6979 295 12745 5457 11945 479 5251 36 25528 2156 253 111 8593 4839 25606 5149 479 8932 44273 36 49125 2156 8593 2156 741 2156 160 2156 295 12745 4839 25606 8593 49371 295 12745 25606 671 295 12745 25606 35524 1493 114 36 5375 4839 25522 6979 295 12745 5457 11 479 1166 36 49125 2156 34300 2156 11945 479 5251 36 25528 2156 28066 12413 13181 208 41697 4839 4839 25606 114 36 295 12745 8061 34300 4839 25522 5149 479 8932 44273 36 49125 2156 34300 2156 741 2156 160 2156 295 12745 4839 25606 35524 671 295 12745 25606 35524 1493 25522 671 11 479 1166 36 741 2156 160 2156 25528 4839 25606 35524 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'When', '_does', '_values', '_read', '_if', '_the', '_end', '_of', '_stream', '_/', '_block', '_data', '_has', '_been', '_reached', '_if', '_the', '_end', '_of', '_stream', '_/', '_block', '_data', '_has', '_been', '_reached', '_into', '_an', '_intermediate', '_buffer', '_to', '_avoid', '_exposing', '_a', '_reference', '_to', '_b', '_)', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 1779 473 3266 1166 114 5 253 9 4615 1589 1803 414 34 57 1348 114 5 253 9 4615 1589 1803 414 34 57 1348 88 41 21398 21944 7 1877 17902 10 5135 7 741 4839 17487 2 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:*** Example ***\n",
            "INFO:__main__:idx: 4\n",
            "INFO:__main__:source_tokens: ['<s>', 'at', '_offset', '_off', '</s>', 'att', 'empt', 's', '_to', '_read', '_len', '_bytes', '_into', '_byte', '_array', '_b', '_at', '_offset', '_off', '_.', '_returns', '_the', '_number', '_of', '_bytes', '_read', '_,', '_or', '_-', '_1', '_if', '_the', '_end', '_of', '_stream', '_/', '_block', '_data', '_has', '_been', '_reached', '_.', '_if', '_copy', '_is', '_true', '_,', '_reads', '_values', '_into', '_an', '_intermediate', '_buffer', '_before', '_copying', '_them', '_to', '_b', '_(', '_to', '_avoid', '_exposing', '_a', '_reference', '_to', '_b', '_)', '_.', '</s>', 'int', '_read', '_(', '_byte', '_[', '_]', '_b', '_,', '_int', '_off', '_,', '_int', '_len', '_,', '_boolean', '_copy', '_)', '_throws', '_IO', '_Exception', '_{', '_if', '_(', '_len', '_==', '_NUM', '_)', '_{', '_return', '_NUM', '_;', '_}', '_else', '_if', '_(', '_bl', 'km', 'ode', '_)', '_{', '_if', '_(', '_pos', '_==', '_end', '_)', '_{', '_refill', '_(', '_)', '_;', '_}', '_if', '_(', '_end', '_<', '_NUM', '_)', '_{', '_return', '_-', '_NUM', '_;', '_}', '_int', '_n', 'read', '_=', '_Math', '_.', '_min', '_(', '_len', '_,', '_end', '_-', '_pos', '_)', '_;', '_System', '_.', '_array', 'copy', '_(', '_buf', '_,', '_pos', '_,', '_b', '_,', '_off', '_,', '_n', 'read', '_)', '_;', '_pos', '_+=', '_n', 'read', '_;', '_return', '_n', 'read', '_;', '_}', '_else', '_if', '_(', '_copy', '_)', '_{', '_int', '_n', 'read', '_=', '_in', '_.', '_read', '_(', '_buf', '_,', '_NUM', '_,', '_Math', '_.', '_min', '_(', '_len', '_,', '_MAX', '_BL', 'OCK', '_S', 'IZE', '_)', '_)', '_;', '_if', '_(', '_n', 'read', '_>', '_NUM', '_)', '_{', '_System', '_.', '_array', 'copy', '_(', '_buf', '_,', '_NUM', '_,', '_b', '_,', '_off', '_,', '_n', 'read', '_)', '_;', '_}', '_return', '_n', 'read', '_;', '_}', '_else', '_{', '_return', '_in', '_.', '_read', '_(', '_b', '_,', '_off', '_,', '_len', '_)', '_;', '_}', '_}', '</s>']\n",
            "INFO:__main__:source_ids: 0 415 6147 160 2 2611 15318 29 7 1166 25528 46487 88 47893 8932 741 23 6147 160 479 2886 5 346 9 46487 1166 2156 50 111 112 114 5 253 9 4615 1589 1803 414 34 57 1348 479 114 5375 16 1528 2156 7005 3266 88 41 21398 21944 137 34236 106 7 741 36 7 1877 17902 10 5135 7 741 4839 479 2 2544 1166 36 47893 646 27779 741 2156 6979 160 2156 6979 25528 2156 49378 5375 4839 6989 38266 47617 25522 114 36 25528 45994 34300 4839 25522 671 34300 25606 35524 1493 114 36 3089 7203 4636 4839 25522 114 36 8593 45994 253 4839 25522 40453 36 4839 25606 35524 114 36 253 28696 34300 4839 25522 671 111 34300 25606 35524 6979 295 12745 5457 11945 479 5251 36 25528 2156 253 111 8593 4839 25606 5149 479 8932 44273 36 49125 2156 8593 2156 741 2156 160 2156 295 12745 4839 25606 8593 49371 295 12745 25606 671 295 12745 25606 35524 1493 114 36 5375 4839 25522 6979 295 12745 5457 11 479 1166 36 49125 2156 34300 2156 11945 479 5251 36 25528 2156 28066 12413 13181 208 41697 4839 4839 25606 114 36 295 12745 8061 34300 4839 25522 5149 479 8932 44273 36 49125 2156 34300 2156 741 2156 160 2156 295 12745 4839 25606 35524 671 295 12745 25606 35524 1493 25522 671 11 479 1166 36 741 2156 160 2156 25528 4839 25606 35524 35524 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:__main__:target_tokens: ['<s>', 'Where', '_do', '_len', '_bytes', '_read', '_into', '_byte', '_array', '_b', '_?', '</s>']\n",
            "INFO:__main__:target_ids: 0 13841 109 25528 46487 1166 88 47893 8932 741 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:__main__:target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "INFO:__main__:***** Running training *****\n",
            "INFO:__main__:  Num examples = 73000\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  Num epoch = 20\n",
            "epoch 0 loss 3.9428: 100% 2282/2282 [24:33<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 8.9174\n",
            "INFO:__main__:  global_step = 2283\n",
            "INFO:__main__:  train_loss = 3.9428\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:8.9174\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 46.22 | rouge_l = 65.37 | meteor = 27.83 | EM = 23.20 | Precision = 74.83 | Recall = 64.73 | F1 = 67.89 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:46.2161613453212\n",
            "INFO:__main__:  ********************\n",
            "epoch 1 loss 1.4296: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 2.58103\n",
            "INFO:__main__:  global_step = 4565\n",
            "INFO:__main__:  train_loss = 1.4296\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:2.58103\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 66.80 | rouge_l = 81.48 | meteor = 43.06 | EM = 41.60 | Precision = 84.56 | Recall = 83.70 | F1 = 82.43 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:66.79596589158605\n",
            "INFO:__main__:  ********************\n",
            "epoch 2 loss 0.5814: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.60624\n",
            "INFO:__main__:  global_step = 6847\n",
            "INFO:__main__:  train_loss = 0.5814\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.60624\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 80.31 | rouge_l = 89.26 | meteor = 52.97 | EM = 61.50 | Precision = 92.06 | Recall = 89.84 | F1 = 89.98 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:80.31444998132875\n",
            "INFO:__main__:  ********************\n",
            "epoch 3 loss 0.3309: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.49286\n",
            "INFO:__main__:  global_step = 9129\n",
            "INFO:__main__:  train_loss = 0.3309\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.49286\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 82.91 | rouge_l = 91.02 | meteor = 55.80 | EM = 65.40 | Precision = 92.02 | Recall = 92.47 | F1 = 91.41 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:82.91221767952543\n",
            "INFO:__main__:  ********************\n",
            "epoch 4 loss 0.2201: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.408\n",
            "INFO:__main__:  global_step = 11411\n",
            "INFO:__main__:  train_loss = 0.2201\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.408\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 84.53 | rouge_l = 91.66 | meteor = 57.12 | EM = 69.60 | Precision = 93.43 | Recall = 92.60 | F1 = 92.19 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:84.52566904649994\n",
            "INFO:__main__:  ********************\n",
            "epoch 5 loss 0.1692: 100% 2282/2282 [24:31<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.39693\n",
            "INFO:__main__:  global_step = 13693\n",
            "INFO:__main__:  train_loss = 0.1692\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.39693\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 85.53 | rouge_l = 92.01 | meteor = 57.81 | EM = 71.30 | Precision = 94.02 | Recall = 92.61 | F1 = 92.60 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:85.52939720426203\n",
            "INFO:__main__:  ********************\n",
            "epoch 6 loss 0.1352: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.36602\n",
            "INFO:__main__:  global_step = 15975\n",
            "INFO:__main__:  train_loss = 0.1352\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best ppl:1.36602\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.39 | rouge_l = 92.71 | meteor = 59.06 | EM = 71.80 | Precision = 93.73 | Recall = 93.96 | F1 = 93.19 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.38596288606438\n",
            "INFO:__main__:  ********************\n",
            "epoch 7 loss 0.0975: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.37877\n",
            "INFO:__main__:  global_step = 18257\n",
            "INFO:__main__:  train_loss = 0.0975\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.81 | rouge_l = 92.80 | meteor = 58.99 | EM = 73.30 | Precision = 94.02 | Recall = 93.84 | F1 = 93.34 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:86.81054406187074\n",
            "INFO:__main__:  ********************\n",
            "epoch 8 loss 0.0798: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.38584\n",
            "INFO:__main__:  global_step = 20539\n",
            "INFO:__main__:  train_loss = 0.0798\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.67 | rouge_l = 92.80 | meteor = 59.38 | EM = 73.30 | Precision = 93.27 | Recall = 94.35 | F1 = 93.16 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 9 loss 0.0614: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.39358\n",
            "INFO:__main__:  global_step = 22821\n",
            "INFO:__main__:  train_loss = 0.0614\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.53 | rouge_l = 92.76 | meteor = 59.23 | EM = 72.40 | Precision = 93.60 | Recall = 94.11 | F1 = 93.21 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 10 loss 0.0478: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.43703\n",
            "INFO:__main__:  global_step = 25103\n",
            "INFO:__main__:  train_loss = 0.0478\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.57 | rouge_l = 92.74 | meteor = 59.52 | EM = 73.30 | Precision = 93.55 | Recall = 94.20 | F1 = 93.17 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 11 loss 0.0392: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.43177\n",
            "INFO:__main__:  global_step = 27385\n",
            "INFO:__main__:  train_loss = 0.0392\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 86.69 | rouge_l = 92.77 | meteor = 59.43 | EM = 73.70 | Precision = 93.73 | Recall = 93.89 | F1 = 93.17 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 12 loss 0.0318: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.42406\n",
            "INFO:__main__:  global_step = 29667\n",
            "INFO:__main__:  train_loss = 0.0318\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 87.17 | rouge_l = 93.16 | meteor = 60.15 | EM = 74.00 | Precision = 93.84 | Recall = 94.46 | F1 = 93.54 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:87.17475574293286\n",
            "INFO:__main__:  ********************\n",
            "epoch 13 loss 0.0236: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.43447\n",
            "INFO:__main__:  global_step = 31949\n",
            "INFO:__main__:  train_loss = 0.0236\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 87.71 | rouge_l = 93.37 | meteor = 60.57 | EM = 75.20 | Precision = 94.25 | Recall = 94.52 | F1 = 93.77 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:87.70747001304946\n",
            "INFO:__main__:  ********************\n",
            "epoch 14 loss 0.0179: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.46047\n",
            "INFO:__main__:  global_step = 34231\n",
            "INFO:__main__:  train_loss = 0.0179\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 87.56 | rouge_l = 93.24 | meteor = 60.31 | EM = 74.80 | Precision = 93.98 | Recall = 94.48 | F1 = 93.61 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 15 loss 0.0148: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.45816\n",
            "INFO:__main__:  global_step = 36513\n",
            "INFO:__main__:  train_loss = 0.0148\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 87.80 | rouge_l = 93.41 | meteor = 60.73 | EM = 75.50 | Precision = 94.04 | Recall = 94.65 | F1 = 93.71 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:87.80032357388072\n",
            "INFO:__main__:  ********************\n",
            "epoch 16 loss 0.0116: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.46851\n",
            "INFO:__main__:  global_step = 38795\n",
            "INFO:__main__:  train_loss = 0.0116\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 87.53 | rouge_l = 93.29 | meteor = 60.39 | EM = 75.50 | Precision = 93.97 | Recall = 94.65 | F1 = 93.68 | \n",
            "INFO:__main__:  ********************\n",
            "epoch 17 loss 0.0085: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.47737\n",
            "INFO:__main__:  global_step = 41077\n",
            "INFO:__main__:  train_loss = 0.0085\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 87.99 | rouge_l = 93.46 | meteor = 60.65 | EM = 75.90 | Precision = 94.18 | Recall = 94.65 | F1 = 93.83 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:87.98996832332674\n",
            "INFO:__main__:  ********************\n",
            "epoch 18 loss 0.0066: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.48441\n",
            "INFO:__main__:  global_step = 43359\n",
            "INFO:__main__:  train_loss = 0.0066\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 88.07 | rouge_l = 93.48 | meteor = 60.89 | EM = 76.10 | Precision = 94.17 | Recall = 94.79 | F1 = 93.85 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:  Best bleu:88.0743770046451\n",
            "INFO:__main__:  ********************\n",
            "epoch 19 loss 0.005: 100% 2282/2282 [24:30<00:00,  1.55it/s]\n",
            "INFO:__main__:\n",
            "***** Running evaluation *****\n",
            "INFO:__main__:  Num examples = 9125\n",
            "INFO:__main__:  Batch size = 32\n",
            "INFO:__main__:  eval_ppl = 1.47969\n",
            "INFO:__main__:  global_step = 45641\n",
            "INFO:__main__:  train_loss = 0.005\n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:dev set: bleu = 87.88 | rouge_l = 93.38 | meteor = 60.74 | EM = 75.70 | Precision = 94.09 | Recall = 94.75 | F1 = 93.80 | \n",
            "INFO:__main__:  ********************\n",
            "INFO:__main__:\n",
            "***** Running Test *****\n",
            "INFO:__main__:Test file: ../data/test/\n",
            "100% 286/286 [17:16<00:00,  3.63s/it]\n",
            "INFO:__main__:test set: bleu = 87.77 | rouge_l = 93.31 | meteor = 60.47 | EM = 75.34 | Precision = 94.12 | Recall = 94.65 | F1 = 93.71 | \n",
            "INFO:__main__:  ********************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following shell if you want to load model that has been build and run test. You don't need to run it again becuase test has been carried out in above execution."
      ],
      "metadata": {
        "id": "fKHFKQE7UbhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Test\n",
        "#!bash java_script_test.sh 0 cbQG"
      ],
      "metadata": {
        "id": "ghuwcDAaOr6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip the output so that you can download all files at once"
      ],
      "metadata": {
        "id": "B37CzUi2pqiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/model-output.zip /content/codeBERT-QG/output/model"
      ],
      "metadata": {
        "id": "0oYlpgK_pw6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code helps you to copy your output to your goole drive"
      ],
      "metadata": {
        "id": "306nwvv_qtg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# copy it there\n",
        "!cp /content/model-output.zip /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "EmGUz8mwq04v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute following command if need inforamtion of system used for training."
      ],
      "metadata": {
        "id": "16oSLV0dUunh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use this command to see GPU activity while doing Deep Learning tasks, for this command 'nvidia-smi' and for above one to work, go to 'Runtime > change runtime type > Hardware Accelerator > GPU'\n",
        "!nvidia-smi\n",
        "!nvidia-smi -L\n",
        "!lscpu |grep 'Model name'\n",
        "#no.of cores each processor is having \n",
        "!lscpu | grep 'Core(s) per socket:'\n",
        "#memory that we can use\n",
        "!free -h --si | awk  '/Mem:/{print $2}'\n",
        "#hard disk space that we can use\n",
        "!df -h / | awk '{print $4}'\n",
        "#no.of sockets i.e available slots for physical processors\n",
        "!lscpu | grep 'Socket(s):'\n",
        "!lscpu | grep \"L3 cache\" \n",
        "#if it had turbo boost it would've shown Min and Max MHz also but it is only showing current frequency this means it always operates at shown frequency\n",
        "!lscpu | grep \"MHz\""
      ],
      "metadata": {
        "id": "jloTmRB9Ka16",
        "outputId": "7fdd00f8-eda0-4882-958d-390dbbdec7c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  5 06:15:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-6f418387-8f8f-ff8b-895e-fe8dcc54a3b3)\n",
            "Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Core(s) per socket:              6\n",
            "85G\n",
            "Avail\n",
            "141G\n",
            "Socket(s):                       1\n",
            "L3 cache:                        38.5 MiB\n",
            "CPU MHz:                         2200.206\n"
          ]
        }
      ]
    }
  ]
}